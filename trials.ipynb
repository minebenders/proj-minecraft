{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System for predicting trials outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pull out the paragraphs of a valid document\n",
    "2. run search engine to find relevant paragraphs\n",
    "3. concatenate relevant paragraphs into a new \"source\" document\n",
    "4. feed source and question into QnA model, get answer.\n",
    "5. manually evaluate if the answer is able to answer the question.\n",
    "6. auto evaluate if the predicted answer is the same or overlaps with the ground-truth answer.\n",
    "7. repeat 1-6 for every doc and every question we want to test.\n",
    "\n",
    "* we start with questions about whether the accused was convicted. find one good phrasing.\n",
    "* can consider testing other phrasings for the same question as well.\n",
    "* then we identify other high-prio questions to test.\n",
    "* tabulate model's accuracy in answering each type of question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor as AllenNLPPredictor\n",
    "\n",
    "class PythonPredictor:\n",
    "    def __init__(self, config=None):\n",
    "        self.predictor = AllenNLPPredictor.from_path(\n",
    "            \"../pretrained/bidaf-elmo-model-2018.11.30-charpad.tar.gz\"\n",
    "        )\n",
    "\n",
    "    def predict(self, payload, full=False):\n",
    "        \"\"\"\n",
    "        :param payload: dict containing the keys \"passage\" and \"question\" - both keys point to string values. \n",
    "        \"passage\" refers to the source doc that the model will look at while \"question\" refers to the question \n",
    "        asked to the model.\n",
    "        :returns: a string representing the most probable answer, according to the model.\n",
    "        \"\"\"\n",
    "        prediction = self.predictor.predict(\n",
    "            passage=payload[\"passage\"], question=payload[\"question\"]\n",
    "        )\n",
    "        if full:\n",
    "            return prediction\n",
    "        else:\n",
    "            return prediction[\"best_span_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_jsonnet not loaded, treating C:\\Users\\Melvin\\AppData\\Local\\Temp\\tmp3j9zt5sp\\config.json as json\n",
      "_jsonnet not loaded, treating snippet as json\n",
      "C:\\Users\\Melvin\\Desktop\\Misc\\Programming\\Proj MineCraft\\proj-minecraft\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "C:\\Users\\Melvin\\Desktop\\Misc\\Programming\\Proj MineCraft\\proj-minecraft\\env\\lib\\site-packages\\allennlp\\data\\token_indexers\\token_characters_indexer.py:56: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "allennlp.predictors.bidaf.BidafPredictor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = PythonPredictor()\n",
    "type(predictor.predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['passage_question_attention', 'span_start_logits', 'span_start_probs', 'span_end_logits', 'span_end_probs', 'best_span', 'best_span_str', 'question_tokens', 'passage_tokens'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rejected Ko’s defence that he did not know that what he was carrying was diamorphine. Accordingly, they convicted the appellants. Against the convictions, this appeal was brought. At the conclusion we dismissed it'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example prediction\n",
    "payload = {\n",
    "    \"passage\": \"The trial judges accepted that both the appellants had come into Singapore only with a view to boarding a flight to Amsterdam the next day. They, however, rejected the submission made on behalf of the appellants that bringing drugs into Singapore with a view solely of exporting them would not be an offence under s 7 of the Act. They also rejected Ko’s defence that he did not know that what he was carrying was diamorphine. Accordingly, they convicted the appellants. Against the convictions, this appeal was brought. At the conclusion we dismissed it, and we now give our reasons.Ground (a) can be disposed of very briefly. By s 18(2) of the Act a rebuttable presumption arose that Ko knew the nature of the drug that he was carrying. Once the presumption arose, the onus of discharging it was on Ko. Having heard Ko’s defence, the trial judges were satisfied that he had not discharged the presumption. We have reviewed the record and it is clear that the trial judges were entitled on the evidence before them to arrive at this finding. We saw no reason to interfere.and submitted that s 7 was applicable only when it was sought to punish a master or captain who had contravened s 20. We could not accept that submission. In common with a number of other similar provisions in the Act, what s 20 does is to raise a presumption as to knowledge. By s 20, if it is proved that a drug was found in a ship or aircraft, then the presumption would arise that the drug was imported in the ship or aircraft with the knowledge of the master or captain. No doubt, in such a case, a master or captain may be charged for violating s 7 of the Act but that does not mean to say that s 7 is confined in its operations only to the master of a ship or captain of an aircraft used for the import of drugs. We see no reason why s 7 should not operate against (say) a passenger in a ship or aircraft who was importing drugs. Against such a passenger the presumption under s 20 as to knowledge would obviously not be applicable but (as in this case) the presumption under s 18(2) would apply.\",\n",
    "    \"question\": \"was the appeal dismissed?\"\n",
    "}\n",
    "prediction = predictor.predict(payload, full=True)\n",
    "print(prediction.keys())\n",
    "prediction['best_span_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class primitiveSearchEngine:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def and_search(self, itr, queries):\n",
    "        \"\"\"\n",
    "        Searches for the passages/paragraphs that contain a \n",
    "        co-occurence of the exact query terms, in any order.\n",
    "        \n",
    "        :params itr: a dict containing strings to search through.\n",
    "        :params queries: a list of query terms.\n",
    "        :returns: a dict of the form, {key: search_result}.\n",
    "        \"\"\"\n",
    "        regex = \"^\"\n",
    "        for term in queries:\n",
    "            # regex = regex + term + '|'\n",
    "            regex = regex + rf\"(?=.*\\b{term}\\b)\"\n",
    "        regex = regex + \".*$\"\n",
    "        \n",
    "        # note: this regex pattern searches for the co-occurence of the\n",
    "        # exact specified terms, in any order.\n",
    "        \n",
    "        pattern = re.compile(regex)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for k, v  in itr.items():\n",
    "            match = pattern.search(v)\n",
    "            \n",
    "            if match:\n",
    "                results[k] = v\n",
    "        return results\n",
    "    \n",
    "    def or_search(self, itr, queries):\n",
    "        \"\"\"\n",
    "        Searches for the paragraphs/strings that contain any of the query terms.\n",
    "        \n",
    "        :params itr: a dict containing strings to search through. they key can be a para number.\n",
    "        :params queries: a list of query terms.\n",
    "        :returns: a dict of the form, {key: search_result}.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for k, v  in itr.items():\n",
    "            for term in queries:\n",
    "                if term in v:\n",
    "                    results[k] = v\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def rule1(self, itr, queries, scorethreshold):\n",
    "        \"\"\"\n",
    "        Rule 1 is an OR search and gives an equal weightage to each keyword\n",
    "        \n",
    "        :param scorethreshold: integer. min number of relevant terms that must appear in \n",
    "        a text (could be a paragaph). \n",
    "        :returns: a dictionary. keys are a subset of itr.keys() and ea value is rule1's \n",
    "        relevance score.\n",
    "        \"\"\"\n",
    "        output = dict()\n",
    "        for para in itr:\n",
    "            score = 0\n",
    "            for word in queries:\n",
    "                if word in itr[para]:\n",
    "                    score += 1 \n",
    "            if score >= scorethreshold: \n",
    "                output[para] = score\n",
    "\n",
    "        output = {k: v for k, v in sorted(output.items(), key=lambda x: x[1], reverse=True)}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def tokenise(string): # works on any arbitrary string\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(string):\n",
    "        for token in word_tokenize(sentence):\n",
    "            tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "def stem(token): # tokenizes any particular token\n",
    "    return PorterStemmer().stem(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions on documents with 1 simple type of question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "# with open('data/cases.json') as f:\n",
    "#     cases = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TestCaseExtractor import TestCaseExtractor\n",
    "tester = TestCaseExtractor(path='data/cases.json')\n",
    "output_df = tester.output_df_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ref</th>\n",
       "      <th>case_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Court</th>\n",
       "      <th>coram</th>\n",
       "      <th>counsel</th>\n",
       "      <th>listed_parties</th>\n",
       "      <th>accused</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1989] SGHC 75 GOH AH LIM</td>\n",
       "      <td>Criminal Case No 6 of 1988</td>\n",
       "      <td>1989-08-24</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[Lai Kew Chai J, F A Chua J]</td>\n",
       "      <td>{'prosecution': ['Lee Sing Lit'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Goh Ah Lim]</td>\n",
       "      <td>Goh Ah Lim</td>\n",
       "      <td>{'1': 'The accused, a male Chinese aged 46, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1989] SGHC 9 KADIR BIN AWANG</td>\n",
       "      <td>Criminal Case No 2 of 1988</td>\n",
       "      <td>1989-02-03</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[T S Sinnathuray J, Joseph Grimberg JC]</td>\n",
       "      <td>{'prosecution': ['Lee Sing Lit'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Kadir bin Awang]</td>\n",
       "      <td>Kadir bin Awang</td>\n",
       "      <td>{'1': 'Kadir bin Awang (“the accused”) was cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1990] SGHC 18 KO MUN CHEUNG</td>\n",
       "      <td>Criminal Case No 17 of 1988</td>\n",
       "      <td>1990-03-15</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[Chan Sek Keong J, Yong Pung How J]</td>\n",
       "      <td>{'prosecution': ['Seng Kwang Boon'], 'defence'...</td>\n",
       "      <td>[Public Prosecutor, Ko Mun Cheung and another]</td>\n",
       "      <td>Ko Mun Cheung and another</td>\n",
       "      <td>{'1': 'You, Ko Mun Cheung, Raymond, (“Ko”) are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1991] SGCA 14 SIM AH CHEOH</td>\n",
       "      <td>Criminal Appeal No 12 of 1988</td>\n",
       "      <td>1991-05-31</td>\n",
       "      <td>SGCA</td>\n",
       "      <td>[Yong Pung How CJ, Chan Sek Keong J, L P Thean J]</td>\n",
       "      <td>{'prosecution': ['Chan Seng Onn'], 'defence': ...</td>\n",
       "      <td>[Sim Ah Cheoh and others, Public Prosecutor]</td>\n",
       "      <td>Sim Ah Cheoh and others</td>\n",
       "      <td>{'1': 'The first appellant, Sim Ah Cheoh (“Sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1991] SGHC 147 NG CHONG TECK</td>\n",
       "      <td>Criminal Case No 63 of 1990</td>\n",
       "      <td>1991-10-12</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[P Coomaraswamy J, Kan Ting Chiu JC]</td>\n",
       "      <td>{'prosecution': ['Ong Hian Sun'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Ng Chong Teck]</td>\n",
       "      <td>Ng Chong Teck</td>\n",
       "      <td>{'1': 'The accused was tried before us and con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      unique_ref                        case_id       date  \\\n",
       "0      [1989] SGHC 75 GOH AH LIM     Criminal Case No 6 of 1988 1989-08-24   \n",
       "1  [1989] SGHC 9 KADIR BIN AWANG     Criminal Case No 2 of 1988 1989-02-03   \n",
       "2   [1990] SGHC 18 KO MUN CHEUNG    Criminal Case No 17 of 1988 1990-03-15   \n",
       "3    [1991] SGCA 14 SIM AH CHEOH  Criminal Appeal No 12 of 1988 1991-05-31   \n",
       "4  [1991] SGHC 147 NG CHONG TECK    Criminal Case No 63 of 1990 1991-10-12   \n",
       "\n",
       "  Court                                              coram  \\\n",
       "0  SGHC                       [Lai Kew Chai J, F A Chua J]   \n",
       "1  SGHC            [T S Sinnathuray J, Joseph Grimberg JC]   \n",
       "2  SGHC                [Chan Sek Keong J, Yong Pung How J]   \n",
       "3  SGCA  [Yong Pung How CJ, Chan Sek Keong J, L P Thean J]   \n",
       "4  SGHC               [P Coomaraswamy J, Kan Ting Chiu JC]   \n",
       "\n",
       "                                             counsel  \\\n",
       "0  {'prosecution': ['Lee Sing Lit'], 'defence': [...   \n",
       "1  {'prosecution': ['Lee Sing Lit'], 'defence': [...   \n",
       "2  {'prosecution': ['Seng Kwang Boon'], 'defence'...   \n",
       "3  {'prosecution': ['Chan Seng Onn'], 'defence': ...   \n",
       "4  {'prosecution': ['Ong Hian Sun'], 'defence': [...   \n",
       "\n",
       "                                   listed_parties                    accused  \\\n",
       "0                 [Public Prosecutor, Goh Ah Lim]                 Goh Ah Lim   \n",
       "1            [Public Prosecutor, Kadir bin Awang]            Kadir bin Awang   \n",
       "2  [Public Prosecutor, Ko Mun Cheung and another]  Ko Mun Cheung and another   \n",
       "3    [Sim Ah Cheoh and others, Public Prosecutor]    Sim Ah Cheoh and others   \n",
       "4              [Public Prosecutor, Ng Chong Teck]              Ng Chong Teck   \n",
       "\n",
       "                                          paragraphs  \n",
       "0  {'1': 'The accused, a male Chinese aged 46, fa...  \n",
       "1  {'1': 'Kadir bin Awang (“the accused”) was cha...  \n",
       "2  {'1': 'You, Ko Mun Cheung, Raymond, (“Ko”) are...  \n",
       "3  {'1': 'The first appellant, Sim Ah Cheoh (“Sim...  \n",
       "4  {'1': 'The accused was tried before us and con...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ref</th>\n",
       "      <th>case_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Court</th>\n",
       "      <th>coram</th>\n",
       "      <th>counsel</th>\n",
       "      <th>listed_parties</th>\n",
       "      <th>accused</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1989] SGHC 75 GOH AH LIM</td>\n",
       "      <td>Criminal Case No 6 of 1988</td>\n",
       "      <td>1989-08-24</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[Lai Kew Chai J, F A Chua J]</td>\n",
       "      <td>{'prosecution': ['Lee Sing Lit'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Goh Ah Lim]</td>\n",
       "      <td>Goh Ah Lim</td>\n",
       "      <td>{'1': 'The accused, a male Chinese aged 46, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1989] SGHC 9 KADIR BIN AWANG</td>\n",
       "      <td>Criminal Case No 2 of 1988</td>\n",
       "      <td>1989-02-03</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[T S Sinnathuray J, Joseph Grimberg JC]</td>\n",
       "      <td>{'prosecution': ['Lee Sing Lit'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Kadir bin Awang]</td>\n",
       "      <td>Kadir bin Awang</td>\n",
       "      <td>{'1': 'Kadir bin Awang (“the accused”) was cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1990] SGHC 18 KO MUN CHEUNG</td>\n",
       "      <td>Criminal Case No 17 of 1988</td>\n",
       "      <td>1990-03-15</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[Chan Sek Keong J, Yong Pung How J]</td>\n",
       "      <td>{'prosecution': ['Seng Kwang Boon'], 'defence'...</td>\n",
       "      <td>[Public Prosecutor, Ko Mun Cheung and another]</td>\n",
       "      <td>Ko Mun Cheung and another</td>\n",
       "      <td>{'1': 'You, Ko Mun Cheung, Raymond, (“Ko”) are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1991] SGHC 147 NG CHONG TECK</td>\n",
       "      <td>Criminal Case No 63 of 1990</td>\n",
       "      <td>1991-10-12</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[P Coomaraswamy J, Kan Ting Chiu JC]</td>\n",
       "      <td>{'prosecution': ['Ong Hian Sun'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Ng Chong Teck]</td>\n",
       "      <td>Ng Chong Teck</td>\n",
       "      <td>{'1': 'The accused was tried before us and con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1992] SGHC 17 NG KWOK CHUN</td>\n",
       "      <td>Criminal Case No 60 of 1990</td>\n",
       "      <td>1992-01-31</td>\n",
       "      <td>SGHC</td>\n",
       "      <td>[S Rajendran J, MPH Rubin JC]</td>\n",
       "      <td>{'prosecution': ['Ong Hian Sun'], 'defence': [...</td>\n",
       "      <td>[Public Prosecutor, Ng Kwok Chun and another]</td>\n",
       "      <td>Ng Kwok Chun and another</td>\n",
       "      <td>{'1': 'Ng Kwok Chun (“Ng”), 27 years of age, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      unique_ref                      case_id       date  \\\n",
       "0      [1989] SGHC 75 GOH AH LIM   Criminal Case No 6 of 1988 1989-08-24   \n",
       "1  [1989] SGHC 9 KADIR BIN AWANG   Criminal Case No 2 of 1988 1989-02-03   \n",
       "2   [1990] SGHC 18 KO MUN CHEUNG  Criminal Case No 17 of 1988 1990-03-15   \n",
       "4  [1991] SGHC 147 NG CHONG TECK  Criminal Case No 63 of 1990 1991-10-12   \n",
       "7    [1992] SGHC 17 NG KWOK CHUN  Criminal Case No 60 of 1990 1992-01-31   \n",
       "\n",
       "  Court                                    coram  \\\n",
       "0  SGHC             [Lai Kew Chai J, F A Chua J]   \n",
       "1  SGHC  [T S Sinnathuray J, Joseph Grimberg JC]   \n",
       "2  SGHC      [Chan Sek Keong J, Yong Pung How J]   \n",
       "4  SGHC     [P Coomaraswamy J, Kan Ting Chiu JC]   \n",
       "7  SGHC            [S Rajendran J, MPH Rubin JC]   \n",
       "\n",
       "                                             counsel  \\\n",
       "0  {'prosecution': ['Lee Sing Lit'], 'defence': [...   \n",
       "1  {'prosecution': ['Lee Sing Lit'], 'defence': [...   \n",
       "2  {'prosecution': ['Seng Kwang Boon'], 'defence'...   \n",
       "4  {'prosecution': ['Ong Hian Sun'], 'defence': [...   \n",
       "7  {'prosecution': ['Ong Hian Sun'], 'defence': [...   \n",
       "\n",
       "                                   listed_parties                    accused  \\\n",
       "0                 [Public Prosecutor, Goh Ah Lim]                 Goh Ah Lim   \n",
       "1            [Public Prosecutor, Kadir bin Awang]            Kadir bin Awang   \n",
       "2  [Public Prosecutor, Ko Mun Cheung and another]  Ko Mun Cheung and another   \n",
       "4              [Public Prosecutor, Ng Chong Teck]              Ng Chong Teck   \n",
       "7   [Public Prosecutor, Ng Kwok Chun and another]   Ng Kwok Chun and another   \n",
       "\n",
       "                                          paragraphs  \n",
       "0  {'1': 'The accused, a male Chinese aged 46, fa...  \n",
       "1  {'1': 'Kadir bin Awang (“the accused”) was cha...  \n",
       "2  {'1': 'You, Ko Mun Cheung, Raymond, (“Ko”) are...  \n",
       "4  {'1': 'The accused was tried before us and con...  \n",
       "7  {'1': 'Ng Kwok Chun (“Ng”), 27 years of age, a...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out cases that are definitely trial cases\n",
    "trials_indices = []\n",
    "for i in range(len(output_df)):\n",
    "    if \"criminal case\" in output_df.iloc[i][\"case_id\"].lower():\n",
    "        trials_indices.append(i)\n",
    "    elif output_df.iloc[i][\"Court\"] == 'SGDC':\n",
    "        trials_indices.append(i)\n",
    "\n",
    "cases_df = output_df.iloc[trials_indices]\n",
    "cases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchEngine = primitiveSearchEngine()\n",
    "\n",
    "# Query lists\n",
    "# Note that strings are searched, not words. So \"element\" will also count in \"elements\"; \"rebut\" in \"rebutted\"\n",
    "ConvictionTrialQ = [\"accordingly\", \"acquit\", \"charge\", \"convict\", \"element\", \"guilty\", \"made out\", \"prove\", \"reasonable doubt\", \"reasons\", \"satisfied\", \"sentence\", \"therefore\" ]\n",
    "ConvictionAppealQ = ConvictionTrialQ + [\"affirm\", \"allow\", \"dismiss\"]\n",
    "PresumptionQ = [\"balance of probabilities\", \"evidence\", \"failed to\", \"fails to\", \"MDA\", \"presumption\", \"reasonable doubt\", \"rebut\"]\n",
    "TraffickingQ = PresumptionQ + [\"17(c)\", \"trafficking\"]\n",
    "PossessionQ = PresumptionQ + [\"18(1)\", \"possession\", ]\n",
    "KnowledgeQ = PresumptionQ + [\"18(2)\", \"actual\", \"knowledge\"]\n",
    "CourierQ = [\"33B\", \"certificate\", \"courier\", \"MDA\", \"substantive assistance\"]\n",
    "SentenceQ = [\"cane\", \"caning\", \"convict\", \"death\", \"impose\", \"imprisonment\", \"mandatory\", \"months\", \"punish\", \"sentence\", \"stroke\", \"years\"]\n",
    "\n",
    "#add porter stemming to capture more relevant words.\n",
    "search_terms = ConvictionTrialQ\n",
    "search_terms = [stem(term) for term in search_terms] # remove if stemming doesn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('trials_rules/guilty.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    yes_rules = list(reader)\n",
    "\n",
    "with open('trials_rules/notguilty.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    no_rules = list(reader)\n",
    "    \n",
    "def sentence2outcome(sent):\n",
    "    # TODO: add rule for ambiguous/unclear or '-1'.\n",
    "\n",
    "    for rule in yes_rules[0]:\n",
    "        if rule in sent:\n",
    "            return 1\n",
    "            break\n",
    "\n",
    "    for rule in no_rules[0]:\n",
    "        if rule in sent:\n",
    "            return 0\n",
    "            break\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "def predict_multiple(cases_df, search_terms, print_output=True):\n",
    "    \"\"\"\n",
    "    todo: put under the predictor class.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    sentences = []\n",
    "    outcomes = []\n",
    "    for i in range(len(cases_df)):\n",
    "        print(f\"case {i+1}/{len(cases_df)}\")\n",
    "\n",
    "        accused = cases_df.iloc[i][\"accused\"]\n",
    "        and_index = accused.find(\"and\")\n",
    "        if and_index != -1:\n",
    "            # if 'NAME and others' then cut away ' and others'\n",
    "            accused = accused[0:and_index - 1]\n",
    "\n",
    "        qn = f\"was {accused} found guilty?\"\n",
    "        #qn = f\"was {appellant}'s appeal allowed?\"\n",
    "        # todo: modify this code chunk to ask multiple question-phrasings at once\n",
    "        # instead of only one question-phrasing per document.\n",
    "        \n",
    "        # Find paragraphs related to search terms; can also try finding sentences instead, later on.\n",
    "        # rule1() yields item numbers (e.g. paragraph numbers) that contain ANY of the search terms. \n",
    "        SCORE_THRESHOLD = 2  # arbitrary threshold for \"rule1\"; result must be greater than thres.\n",
    "        results = searchEngine.rule1(cases_df.iloc[i]['paragraphs'], search_terms, SCORE_THRESHOLD)\n",
    "        \n",
    "        # Concatenate top relevant paragraphs into one chunk to feed as input to the QnA model.\n",
    "        combined_psg = \"\"\n",
    "        total_score = 0\n",
    "        MAX_PARAS = 4\n",
    "        num_paras = 0\n",
    "        relevant_paras = list()\n",
    "        if len(results) > 0:    \n",
    "            keys_list = list(results.keys())\n",
    "            max_score = results[keys_list[0]]  # because keys_list is presorted according to\n",
    "            # descending score\n",
    "            for item_num, score in results.items():               \n",
    "                if score == max_score:\n",
    "                    combined_psg = combined_psg + \" \" + cases_df.iloc[i]['paragraphs'][str(item_num)]\n",
    "                    total_score = total_score + score\n",
    "                    num_paras = num_paras + 1\n",
    "                    relevant_paras.append(item_num)\n",
    "                    total_score = total_score + score\n",
    "                elif num_paras < MAX_PARAS:\n",
    "                    combined_psg = combined_psg + \" \" + cases_df.iloc[i]['paragraphs'][str(item_num)]\n",
    "                    num_paras = num_paras + 1\n",
    "                    relevant_paras.append(item_num)\n",
    "                    total_score = total_score + score\n",
    "\n",
    "        sentence_str = 'NA' # prediction defaults to NA if no relevant paras found.\n",
    "        if combined_psg:\n",
    "            payload = {\n",
    "                'passage': combined_psg,\n",
    "                'question': qn\n",
    "            }\n",
    "            prediction = predictor.predict(payload, full=True)\n",
    "            predicted_span = prediction['best_span_str']\n",
    "            span_indices = prediction['best_span']\n",
    "            \n",
    "            tokens = prediction['passage_tokens']\n",
    "            start_index = span_indices[0]\n",
    "            end_index = span_indices[1]\n",
    "            \n",
    "            sent_start_index = start_index\n",
    "            while tokens[sent_start_index] != '.' and sent_start_index > 0:\n",
    "                sent_start_index = sent_start_index - 1\n",
    "            sent_end_index = end_index\n",
    "            while sent_end_index < len(tokens):\n",
    "                if tokens[sent_end_index] != '.':\n",
    "                    sent_end_index = sent_end_index + 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            if tokens[sent_start_index] == '.':\n",
    "                sentence = tokens[sent_start_index + 1 : sent_end_index]\n",
    "            else:\n",
    "                sentence = tokens[sent_start_index : sent_end_index]\n",
    "            detokenizer = TreebankWordDetokenizer()\n",
    "            sentence_str = detokenizer.detokenize(sentence)  # the output is not perfectly formatted.\n",
    "            \n",
    "        preds.append(predicted_span)\n",
    "        sentences.append(sentence_str)\n",
    "        \n",
    "        outcome = sentence2outcome(sentence_str)\n",
    "        outcomes.append(outcome)\n",
    "        \n",
    "        if print_output:\n",
    "            # TODO: use logger.\n",
    "            print(cases_df.iloc[i][\"unique_ref\"])\n",
    "            print(f\"qn: {qn}\")\n",
    "            print(\"relevant paragraphs:\\n\" + combined_psg)\n",
    "            print(f\"relevant paragraph numbers: {relevant_paras}\")\n",
    "            print(f\"keywords score: {total_score}.\")\n",
    "            print()\n",
    "            print(f\"predicted span: {predicted_span}\")\n",
    "            print(f\"full sentence or sequence: {sentence_str}\")\n",
    "            #print(f\"item reference number: {answer_item_num}\")  # determining this isn't straightforward.\n",
    "            #print(f\"start and end indices of tokens in passage: {span_indices}\")\n",
    "            print()\n",
    "    return preds, sentences, outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds, sentences, outcomes = predict_multiple(cases_df[5:7], search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter path to save csv file:\n",
      " data/trials_00.csv\n"
     ]
    }
   ],
   "source": [
    "path = input('enter path to save csv file:\\n')\n",
    "to_save = pd.DataFrame()\n",
    "to_save.insert(0, \"unique_ref\", cases_df['unique_ref'].values)\n",
    "to_save.insert(1, \"raw_answer\", preds)\n",
    "to_save.insert(2, \"final_answer\", sentences)\n",
    "to_save.insert(3, \"outcome\", outcomes)\n",
    "to_save.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert candidate sentences into outcome values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projmc",
   "language": "python",
   "name": "projmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
